---
title: 大模型是智能吗？（随想）
date: 2026-02-21 00:00:00
thumbnail: /images/llm-intelligence.jpg
tags:
---

那么我是否是 Transformer 架构就能实现真正智能的信仰者？换句话说，从一大堆输入而来，经过一堆权重不断预测下一个字的概率这件事本身，是否构成智能？

事实上很多人争论的点已经到哲学层面了，而不是技术层面。关于人类与大模型在预测机制上的共同本质，我在  
<a class="hover-note" href="/2026/02/21/human-repeater/" data-note="这里讨论：人类是否本质上也是预测系统，以及大脑与神经网络的关系。">《人类的本质为什么是复读机？（随想）》</a>  
中已经展开。

甚至继续思考下去，人类的“无语言脑海”，某种程度上也能够被实现。现在的深度思考过程是基于人类语言的，我靠，那么由于世界模型的存在，我们可以分配给现在传统的文字大模型一个混沌的视频流，让它在思考的时候自由发挥，甚至输出每个文字的时候都可以动这个视频流，搞一个超级黑盒，人类无法解读的无监督学习，会不会产生更可怕的智能？

我靠，我的确是自发想到这一点的。我去搜索了一下，<a href="https://openreview.net/pdf?id=BZ5a1r-kVsf" target="_blank">Yann LeCun 在《A Path Towards Autonomous Machine Intelligence》中提出的 JEPA 路线</a>刚好和这个完全一致。这太疯狂了。这是绝对正确的方向，能做出真正的AGI。

这样看来，现在的全文字，和多模态输入模型，只是AI发展史上面的小小弯路，甚至不是弯路，是必经之路罢了。人类在这个路线上持续发力，做出人类终将无法理解的AGI只是时间问题。人类将不再是宇宙当中（自认为的）唯一高智慧生命了。

关于人类的偏见如何影响AI的发展方向，以及AI对齐可能带来的问题，可以见  
<a class="hover-note" href="/2026/02/21/human-echo/" data-note="这里会讨论：人类认知偏差、over-mirroring和信息茧房。">《人类和AI终将互相训练》（随想）</a>。