---
title: 大模型是智能吗？（随想）
date: 2026-02-21 00:00:00
tags:
---

那么我是否是transformer结构就能实现真正智能的信仰者？换句话说，从一大堆输入而来，经过一堆权重不断预测下一个字的概率这件事本身，是否构成智能？

事实上很多人争论的点已经到哲学层面了，而不是技术层面。我们先看不停预测下一个字这件事。人类在无法逆转的时间长河当中，只拥有眼前的一瞬，我们从来无法验证过去是否存在，过去只存在于记忆里面。能够证明这个的就是五分钟世界假说 (Five-minute Hypothesis)。我们以人类细胞的运行速度预测下一个瞬间我们要说什么，该做什么，呼气还是吸气。在我眼里这和AI预测下一个字并没有什么区别。除了AI的运行速度被机器的运算速度，GPU频率有「间接」关系。所以在运行逻辑上，我觉得AI和人类是完全相同的。

至于多层多维度矩阵，人类的大脑更是如此。之前那篇文章里面写了有关人类大脑为什么跟AI权重本质一致。（节选：那人类真的和大模型不一样吗？但你从最初始的角度来看，婴儿和一个全随机参数的初始权重来说也并没有什么区别。都是靠后天的，大量接触完全陌生的东西，来让神经元逐渐建立链接，产生某种“意义”。人类和AI一样都是多模态模型，想办法最终想出一个解释自己的输入输出的办法。眼睛所看，耳朵所听，皮肤所触，最终变成一些密密麻麻的电信号经由神经被传输给大脑这个不知道多少层多少参数的混沌模型，然后通过身体输出。AI更是一样，尤其是多模态模型，图片和声音被转换为向量，跟文字被拼到一起一起送入模型，图片甚至没有被OCR，而是直接进入了模型这个脑子里，这太奇妙了。这跟人类确实是没什么区别。）

甚至继续思考下去，人类的“无语言脑海”，某种程度上也能够被实现。现在的深度思考过程是基于人类语言的，我靠，那么由于世界模型的存在，我们可以分配给现在传统的文字大模型一个混沌的视频流，让它在思考的时候自由发挥，甚至输出每个文字的时候都可以动这个视频流，搞一个超级黑盒，人类无法解读的无监督学习，会不会产生更可怕的智能？

我靠，我的确是自发想到这一点的。我去搜索了一下，Yann LeCun提出的JEPA刚好和这个完全一致。这太疯狂了。这是绝对正确的方向，能做出真正的AGI。这样看来，现在的全文字，和多模态输入模型，只是AI发展史上面的小小弯路，甚至不是弯路，是必经之路罢了。