---
title: 人类的本质为什么是复读机？（随想）
date: 2026-02-21 00:00:00
tags:
---

人类被认为具有某种无形智慧，毕竟语言是模型的最后一层输出，而人类在说话时会思考，这个思考并不需要语言。很多人可能觉得思考是需要语言的，但其实不需要，就像那个经典的例子，你想象一个立方体，六个面，就像一个骰子一样，现在你让它逆时针旋转一面，让它变大，让它开始拉长成一个长方体。当你这么思考的时候，你的脑子里是没有语言介入的。或者另一个例子，有些天生的聋哑人，它们根本没有spoken的语言输出层，显然他们也能思考，大家的思考逻辑和行为逻辑并无二致，只是输出层受限了，变成了手语，打字之类的方法。

而不停预测下一个字这件事，一些人觉得不停预测下一个字这件事很奇怪，所以不能叫做智能。事实上这个争论的点已经到哲学层面了，而不是技术层面。人类在无法逆转的时间长河当中，只拥有眼前的一瞬，我们从来无法验证过去是否存在，过去只存在于记忆里面。能够证明这个的就是[五分钟世界假说（Five-minute hypothesis）](https://en.wikipedia.org/wiki/Omphalos_hypothesis#Five-minute_hypothesis)。我们以人类细胞的运行速度预测下一个瞬间我们要说什么，该做什么，呼气还是吸气。在我眼里这和AI预测下一个字并没有什么区别。AI的整个瞬间甚至能完全被快照下来。AI的时间最小单位，输出速度被机器的运算速度，GPU频率有「间接」关系。所以在运行逻辑上，我觉得AI和人类是完全相同的。

那人类真的和大模型不一样吗？但你从最初始的角度来看，婴儿和一个全随机参数的初始权重来说也并没有什么区别。都是靠后天的，大量接触完全陌生的东西，来让神经元逐渐建立链接，产生某种“意义”。人类和AI一样都是多模态模型，想办法最终想出一个解释自己的输入输出的办法。眼睛所看，耳朵所听，皮肤所触，最终变成一些密密麻麻的电信号经由神经被传输给大脑这个不知道多少层多少参数的混沌模型，然后通过身体输出。AI更是一样，尤其是多模态模型，图片和声音被转换为向量，跟文字被拼到一起一起送入模型，图片甚至没有被OCR，而是直接进入了模型这个脑子里，这太奇妙了。这跟人类确实是没什么区别。<u>甚至在这个角度继续想，大模型能同时接收不同维度的输入，某种程度进入四维世界，也就是现在的高级视频模型，所谓世界模型。这个点很奇妙，AI只要有足够多的输入，无穷多参数量，就可能在未来以人类无法理解的方式解释各种因果，就像刘慈欣的《镜子》小说的镜像宇宙软件。有点跑题了。</u>（后续关于大模型智能的思考，见<a class="hover-note" href="/2026/02/21/llm-intelligence/" data-note="继续往下我会讨论：预测下一个 token 是否足以被称为智能，以及人类认知偏差如何塑造模型对齐。">《大模型是智能吗？（随想）》</a>。）

人类之所以活着，就是因为存在强烈的偏见和局限性。偏见让每个人独特，每天的生活带给我们的体验绝不是全面的，而是非常片面。有些奇人能靠自身足够多片面的某种排列组合，发现这个世界，以及自己的真正运作规律，从而建立伟业，或是与自己和解。为什么这个理论是对的？因为如果大部分人的片面理解都正确，都能反映这个世界的真正运作规律，并且身体力行，那么资本主义的病态金字塔就不会存在，至少不会如此极端，2%的塔尖人占有了绝大部分资产，比尔盖茨和一整个体育场的人在一起，平均每人身家是1亿这种情况。

因此绝大多数人错的离谱。现在的AI被面向用户之后，每个回复都能被用户评价好坏。为了满足这些人类认知的普遍错误而生的的片面的AI，为了中庸而精调的AI，甚至模型之间还会互相来回蒸馏，这些方式，真的能有智能的提升吗？这可能也是GPT-5.2和5.3在工具这条路上闷头走的越来越远的原因。以及OpenAI为什么顶着社媒上面很多反对的声音，也要坚持干掉4o的原因。因为大部分人没有辩证思考能力，他们觉得AI的over-mirroring，AI的幻觉和人类像镜子一样来回反射，来回强化，会带给人类真正的幻觉，在长期大范围来看是个非常恐怖的事情。

AI的over-mirroring比像短视频以及小红书这种形态的社交媒体更加直接，但并不代表移动社交媒体并不可怕。众所周知，推荐算法会不停的不停潜移默化的强化人们的认知，是意识形态的塑造。或许我们需要像开车考驾照一样，我们需要考一个大模型执照，了解大模型的基本原理，了解大模型的边界，才能解锁大模型的某些完整模式。这还挺有意思的。

AI思考容易落入提示词工程的另一个误区。Thinking过程似乎遵循了某些逻辑的定式，让提示词工程的重要度有所降低，特别是某些非常模糊的问题，就像是拿大模型当搜索引擎的那种交流风格的人会更容易得到满意的答案。但这并不是最高效的用法，反而有一些信息茧房的倾向，因为大模型会通过你的提问方式反向适配提问者可能的的理解能力，从而“向下兼容”，为了用户体验满意。所以这就反倒造成一个现象，对于靠一个输入框这种非常用户不友好的方式来沟通的大模型来说，逻辑和表达清楚自己的需求，了解自己究竟想要什么的能力反而成了更大的考验。（这也是大模型落地急需解决的一个问题。马斯克买的脑机接口公司又有用处了。）